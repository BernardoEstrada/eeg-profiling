{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XJUw5pC8uBdyBsInK1ZcKNubPyznKDrH",
      "authorship_tag": "ABX9TyMwot8rxslKDsRdYWU8Ev93",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BernardoEstrada/eeg-profiling/blob/main/data_transformation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O4dvnDlb-Xuy",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Copy dataset from Drive\n",
        "# Run this block if you have the zip dataset in your drive (EEGMMIDB)\n",
        "#   Remember to change the drive path if the zip is not in the root\n",
        "!mkdir -p /content/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0\n",
        "\n",
        "!unzip -u /content/drive/MyDrive/eeg-motor-movementimagery-dataset-1.0.0 -d /content/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0\n",
        "\n",
        "!mv /content/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/files/* /content/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/.\n",
        "!rm -r /content/mne_data/MNE-eegbci-data/files/eegmmidb/1.0.0/files\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Copy transformed dataset from Drive\n",
        "!mkdir transformed_data\n",
        "!unzip -u /content/drive/MyDrive/tesina/transformed.zip -d /content/transformed_data\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hwgILOwy5pCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install dependencies\n",
        "!pip install mne -q"
      ],
      "metadata": {
        "id": "-2MW3AUKA4ua",
        "cellView": "form"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import dependencies and def util functions\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import mne\n",
        "\n",
        "MNE_PATH = \"/content/mne_data\"\n",
        "\n",
        "def getAnnotationMapping(run: int):\n",
        "  res = {\n",
        "    \"T0\": \"rest\"\n",
        "  }\n",
        "  if run in [3, 4, 7, 8, 11, 12]:\n",
        "    res[\"T1\"] = \"left_fist\"\n",
        "    res[\"T2\"] = \"right_fist\"\n",
        "  if run in [5, 6, 9, 10, 13, 14]:\n",
        "    res[\"T1\"] = \"both_fists\"\n",
        "    res[\"T2\"] = \"both_feet\"\n",
        "  return res\n",
        "\n",
        "tasks = {\n",
        "  \"na\": \"unknown_task\",\n",
        "  \"T0A\": \"baseline_eo\", # baseline, eyes open\n",
        "  \"T0B\": \"baseline_ec\", # baseline, eyes closed\n",
        "  \"T1\": \"mv_one\", # open and close corresponding fist\n",
        "  \"T2\": \"im_one\", # imagine opening and closing the corresponding fist\n",
        "  \"T3\": \"mv_two\", # open and close both fists or both feet\n",
        "  \"T4\": \"im_two\", # imagine opening and closing both fists or both feet\n",
        "}\n",
        "def getTaskFromRun(run: int) -> str:\n",
        "  if run == 1: return tasks[\"T0A\"]\n",
        "  if run == 2: return tasks[\"T0B\"]\n",
        "  try: return tasks[f\"T{(run-2)%4}\"]\n",
        "  except: return tasks[\"na\"]\n",
        "\n",
        "def transformRunData(n_subject, n_run):\n",
        "  # Get data and standarize\n",
        "  f_name = mne.datasets.eegbci.load_data(n_subject, n_run, path=MNE_PATH)[0]\n",
        "  raw = mne.io.read_raw_edf(f_name, preload=True).load_data()\n",
        "  mne.datasets.eegbci.standardize(raw)\n",
        "\n",
        "  # Rename and get events\n",
        "  raw.annotations.rename(getAnnotationMapping(n_run))\n",
        "  events_from_annot, event_dict = mne.events_from_annotations(raw)\n",
        "\n",
        "  # Get event durations\n",
        "  # Set second (end) value on annotations to first (start) value of next item -1\n",
        "  for i in range(len(events_from_annot)):\n",
        "    if i+1<len(events_from_annot):\n",
        "      events_from_annot[i][1] = events_from_annot[i+1][0]-1\n",
        "    else:\n",
        "      events_from_annot[i, 1] = len(raw)\n",
        "\n",
        "  # Get data in np arr\n",
        "  time_data = raw.get_data().transpose()\n",
        "\n",
        "  # Save all events\n",
        "  for ev in event_dict:\n",
        "    events = mne.event.pick_events(events_from_annot, include=[event_dict[ev]])\n",
        "    data = np.array([time_data[e[0]:e[1]][:] for e in events], dtype=object)\n",
        "    path = f'data/S{n_subject:03d}/R{n_run:02d}'\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    np.save(f'{path}/{ev}', data)"
      ],
      "metadata": {
        "id": "aMAY3sufA6vK",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Transforms and zips ALL data. Takes a LONG time, if you already have the archive don't run this cell, use the 2nd cell instead\n",
        "for s in range(109):\n",
        "  for r in range(14):\n",
        "    transformRunData(s+1, r+1)\n",
        "\n",
        "!zip -r transformed.zip data\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SVrCWA_D09Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip -r transformed.zip data\n",
        "!mkdir /content/drive/MyDrive/tesina\n",
        "!mv /content/drive/MyDrive/eeg-motor-movementimagery-dataset-1.0.0.zip /content/drive/MyDrive/tesina/.\n",
        "!cp transformed.zip /content/drive/MyDrive/tesina/."
      ],
      "metadata": {
        "id": "prYgnCgp15nT"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_subjects = 109\n",
        "n_runs = 14\n",
        "n_channels = 64\n",
        "# min 37s\n",
        "# max 181s\n",
        "# mean 114s\n",
        "n_time = 160 * 120\n",
        "\n",
        "epochs = mne.Epochs(raw, events_from_annot, event_id=event_dict, preload=True)"
      ],
      "metadata": {
        "id": "p4JYWLsGI1TH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "# %matplotlib widget\n",
        "\n",
        "# print(ev, data.shape, len(max(data, key=len)), len(min(data, key=len)))"
      ],
      "metadata": {
        "id": "3-MGpJjZy6e9"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}